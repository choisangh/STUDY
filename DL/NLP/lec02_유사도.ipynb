{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "national-embassy",
   "metadata": {},
   "source": [
    "<img src='./img/logo.png'>\n",
    "* ref : https://wikidocs.net/31698,  WikiDoc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-yellow",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 거리 기반 유사도(similarity)\n",
    "* 유클리드 거리(euclidean distance)\n",
    "* 맨해튼 거리(Manhattan distance)\n",
    "* 마할라노비스 거리 (Mahalanobis distance)\n",
    "* 코사인 유사도(cosine similarity)\n",
    "* 문장/문서 간 거리\n",
    "* 군집(집합) 간 거리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-regression",
   "metadata": {},
   "source": [
    "## 유클리드 거리(euclidean distance)\n",
    "### 좌표 상의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-threat",
   "metadata": {},
   "source": [
    "<img src='./img/img5.png' width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-trauma",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 범주형 데이터에 대한 좌표 거리 구하기\n",
    "* get_dummy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-greek",
   "metadata": {},
   "source": [
    "<img src='./img/img6.png' width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-logic",
   "metadata": {},
   "source": [
    "## 맨해튼 거리(Manhattan distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-dollar",
   "metadata": {},
   "source": [
    "<img src='./img/img7.png' width=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-bryan",
   "metadata": {},
   "source": [
    "## 마할라노비스 거리 (Mahalanobis distance) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-avenue",
   "metadata": {},
   "source": [
    "<img src='./img/img8.png'  width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-strength",
   "metadata": {},
   "source": [
    "## 문장 간의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-income",
   "metadata": {},
   "source": [
    "<img src='./img/img9.png'  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-height",
   "metadata": {},
   "source": [
    "## 문서 사이의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-texture",
   "metadata": {},
   "source": [
    "<img src='./img/img10.png'  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-silver",
   "metadata": {},
   "source": [
    "## 군집(집합) 간의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-characterization",
   "metadata": {},
   "source": [
    "<img src='./img/img11.png'  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-variance",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-communications",
   "metadata": {},
   "source": [
    "# 문장/문서 유사도(Vector Similarity)\n",
    "* 각 문서의 단어들을 어떤 방법으로 수치화하여 표현했는지(DTM, Word2Vec 등)\n",
    "* 문서 간의 단어들의 차이를 어떤 방법(유클리드 거리, 코사인 유사도 등)으로 계산했는지\n",
    "* ref : https://www.kernix.com/blog/similarity-measure-of-textual-documents_p12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-uganda",
   "metadata": {},
   "source": [
    "<img src='https://www.kernix.com/doc/articles/overview.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-aircraft",
   "metadata": {},
   "source": [
    "## 카운트 기반의 단어 표현(Count based word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-allen",
   "metadata": {},
   "source": [
    "### Bag of Words(BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-grocery",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 불용언처리 (english)\n",
    "* 사용자 지정\n",
    "* CountVectorizer에서 지원\n",
    "* NLTK에서 지원 :  https://www.nltk.org/data.html\n",
    "* stopwords 다운 압축풀어 venv/nltk_data/corpora/stopwords에 넣기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-announcement",
   "metadata": {},
   "source": [
    "#### 불용언처리 (한글)\n",
    "* https://github.com/stopwords-iso/stopwords-ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-oregon",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 코사인 유사도(Cosine Similarity)\n",
    "* <font color='red'>벡터의 크기가 아니라 방향(패턴)에 초점</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-welcome",
   "metadata": {},
   "source": [
    "<img src='./img/img2.png' width=500><br>\n",
    "<img src='./img/img3.png' width=500><br>\n",
    "<img src='./img/img4.png' width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589b4b38-218f-4211-b312-0c8b7724d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm  #--정규화 ||A||\n",
    "#from numpy import dot\n",
    "\n",
    "def my_cos_sim(A,B):\n",
    "    cos_sim = np.dot(A, B) / (norm(A) * norm(B))\n",
    "    print(cos_sim)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cfd5ff-59c2-4d17-b183-b65ef7329af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067811865476\n",
      "0.7071067811865476\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# sklearn...vectorize.. [1,2,3,]\n",
    "doc1 = [0,1,2,1]\n",
    "doc2 = [1,0,1,1]\n",
    "doc3 = [2,0,2,2]\n",
    "my_cos_sim(doc1,doc2)\n",
    "my_cos_sim(doc1,doc3)\n",
    "my_cos_sim(doc2,doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d71f20-c82e-479b-b002-9c6c454649a4",
   "metadata": {},
   "source": [
    "* 연습 by kms  ** 주의주의..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a3246cc-9472-4242-a13c-512706da4249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 단어에 매겨진 인덱스 값 :  {'나는': 1, '좋아한다': 2, '어제': 3, '비가': 4, '와서': 5, '날씨가': 6, '추워졌다': 7, '고양이를': 8, '강아지를': 9}\n",
      "0.6941980239122336\n",
      "0.6774960231074738\n",
      "0.9995786102379159\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text_list = [\"어제 비가 와서 날씨가 추워졌다.\",\n",
    "             \"나는 고양이를 좋아한다.\",\n",
    "             \"나는 강아지를 좋아한다.\"]\n",
    "\n",
    "# ------ T :  단어분리\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_list)\n",
    "print('각 단어에 매겨진 인덱스 값 : ',tokenizer.word_index)\n",
    "\n",
    "# ------ s :  단어->숫자\n",
    "encoding = tokenizer.texts_to_sequences(text_list)\n",
    "# -------p : 벡터길이 맞추기\n",
    "padding = pad_sequences(sequences=encoding) #, padding='pre')\n",
    "\n",
    "my_cos_sim(padding[0],padding[1])\n",
    "my_cos_sim(padding[0],padding[2])\n",
    "my_cos_sim(padding[1],padding[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bce18-80bc-48d4-9026-8a20340eb3c3",
   "metadata": {},
   "source": [
    "* 연습 by lhl ** BoW ... DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "451b834e-167f-4f37-ba5d-13abe753e186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'어제': 5, '비가': 4, '와서': 6, '날씨가': 3, '추워졌다': 8, '나는': 2, '고양이를': 1, '좋아한다': 7, '강아지를': 0}\n",
      "[0 0 0 1 1 1 1 0 1] [0 1 1 0 0 0 0 1 0] [1 0 1 0 0 0 0 1 0]\n",
      "0.0\n",
      "0.0\n",
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "doc1 = '어제 비가 와서 날씨가 추워졌다.'\n",
    "doc2 = '나는 고양이를 좋아한다.'\n",
    "doc3 = '나는 강아지를 좋아한다.'\n",
    "corpus = [doc1, doc2, doc3]\n",
    "\n",
    "cnt_vt = CountVectorizer()\n",
    "res = cnt_vt.fit_transform(corpus)  #Iterable\n",
    "print(cnt_vt.vocabulary_)    \n",
    "\n",
    "doc1 = res.toarray()[0]\n",
    "doc2 = res.toarray()[1]\n",
    "doc3 = res.toarray()[2]\n",
    "print(doc1, doc2, doc3)\n",
    "      \n",
    "      \n",
    "my_cos_sim(doc1, doc2)\n",
    "my_cos_sim(doc1, doc3)\n",
    "my_cos_sim(doc2, doc3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-responsibility",
   "metadata": {},
   "source": [
    "---\n",
    "### [실습] 영화추천 시스템\n",
    "* ref : https://www.kaggle.com/rounakbanik/the-movies-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-slovenia",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [실습] 지수 변동성 유사도\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-preview",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "union-spread",
   "metadata": {},
   "source": [
    "## 문서 단어 행렬(DTM, Document-Term Matrix)\n",
    "* 각 문서에서 등장한 단어의 빈도를 행렬의 값으로 표기해 서로 다른 문서들을 비교\n",
    "* 다수의 BoW : 각 문서에 대한 BoW를 하나의 행렬로 만든 것\n",
    "\n",
    "* <단점>\n",
    "    - 희소 표현(Sparse representation) : 단어 집합의 크기 == 벡터의 차원이 되고 대부분의 값이 0이 된다\n",
    "    - 단순 빈도 수 기반 접근 : '이다'와 같은 중요하지 않은 최빈도 단어로 문서를 연관지으면??\n",
    "    - <font color='red'> TF-IDF 필요 (DTM에 불용어와 중요한 단어에 대해서 가중치)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-satin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-scheduling",
   "metadata": {},
   "source": [
    "## 단어 빈도-역 문서 빈도(TF-IDF, Term Frequency-Inverse Document Frequency)\n",
    "* 우선 DTM을 만든 후, TF-IDF 가중치를 부여\n",
    "* 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 활용\n",
    "* TF-IDF = TF * IDF\n",
    "\n",
    "* 문서(d), 단어(t), 문서총개수(n)\n",
    "* <font color='red'> $ tf(d,t) $ : 특정 문서 d에서의 특정 단어 t의 등장 횟수</font>\n",
    "* <font color='red'>  $df(t)$ : 특정 단어 t가 등장한 문서의 수 </font>\n",
    "* <font color='red'>  $idf(d, t) = log (\\frac{n}{1+df(t)})$ : df(t) 역수</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "important-allah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['바나나', '길고', '과일이', '노란', '사과', '싶은', '먹고', '저는', '좋아요']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log # IDF계산\n",
    "\n",
    "docs = [\n",
    "  '먹고 싶은 사과',\n",
    "  '먹고 싶은 바나나',\n",
    "  '길고 노란 바나나 바나나',\n",
    "  '저는 과일이 좋아요'\n",
    "] \n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silent-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(t, d): #DTM\n",
    "    return d.count(t)\n",
    "\n",
    "def idf(t):\n",
    "    df = 0\n",
    "    for doc in docs:\n",
    "        df += t in doc\n",
    "    return log(N/(df + 1))\n",
    "\n",
    "def tfidf(t, d):\n",
    "    return tf(t,d)* idf(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-suspension",
   "metadata": {},
   "source": [
    "### TF (TDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-celtic",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-newfoundland",
   "metadata": {},
   "source": [
    "### TF-IDF 행렬 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-museum",
   "metadata": {
    "tags": []
   },
   "source": [
    "---- \n",
    "## [실습] 사이킷런을 이용한 DTM과 TF-IDF\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-sister",
   "metadata": {},
   "source": [
    "* CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a33fe6-5974-4280-833e-99bfaeda65db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "oriental-photograph",
   "metadata": {},
   "source": [
    "* TfidfVectorizer : TF-IDF 계산\n",
    "* (IDF의 로그항의 분자에 1을 더해주며, 로그항에 1을 더해주고, TF-IDF에 L2 정규화라는 방법으로 값을 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cd42a-4670-41db-8b62-87157ba5bdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intended-bearing",
   "metadata": {},
   "source": [
    "# 군집간 유사도(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-lexington",
   "metadata": {},
   "source": [
    "### [실습] 주가 군집 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-local",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "clean-afghanistan",
   "metadata": {},
   "source": [
    "### [실습] K-means를 활용한 Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
